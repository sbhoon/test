{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def step(x):\n",
    "    return np.where(x>0,1,0)\n",
    "def relu(x):\n",
    "    return np.where(x>0,x,0)\n",
    "def softmax(x):\n",
    "    x = x- np.max(x,axis=1).reshape(-1,1)\n",
    "    return np.exp(x)/np.sum(np.exp(x),axis=1).reshape(-1,1)\n",
    "def cross_entropy(y,t):\n",
    "    return -np.sum(t*np.log(y))             \n",
    "def numerical_gradient(f,x) :\n",
    "    h = 1e-4\n",
    "    grads = np.zeros_like(x)\n",
    "    it = np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_x = x[idx]\n",
    "        x[idx] = tmp_x + h\n",
    "        fxh = f(x)\n",
    "        x[idx] = tmp_x\n",
    "        fx = f(x)\n",
    "        grads[idx]  = (fxh-fx)/h\n",
    "        it.iternext()\n",
    "    return grads               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_iris()['data']\n",
    "y = load_iris()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one(x):\n",
    "    data = np.zeros((x.size, np.unique(x).size))\n",
    "    for idx, x in enumerate(x):\n",
    "        data[idx, x] = 1\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = make_one(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(4,10)/2\n",
    "b1 = np.zeros(10)\n",
    "W2 = np.random.randn(10,5)/2\n",
    "b2 = np.zeros(5)\n",
    "W3 = np.random.randn(5,3)/2\n",
    "b3 = np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = np.dot(X,W1) + b1\n",
    "z1 = relu(l1)\n",
    "l2 = np.dot(z1,W2) + b2\n",
    "z2 = relu(l2)\n",
    "l3 = np.dot(z2,W3) + b3\n",
    "pred = softmax(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    l1 = np.dot(X,W1) + b1\n",
    "    z1 = relu(l1)\n",
    "    l2 = np.dot(z1,W2) + b2\n",
    "    z2 = relu(l2)\n",
    "    l3 = np.dot(z2,W3) + b3\n",
    "    pred = softmax(l3)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222.30928432052588"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222.30928432052588"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(predict(X),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient2(f,x) :\n",
    "    h = 1e-4\n",
    "    grads = np.zeros_like(x)\n",
    "    it = np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_x = x[idx]\n",
    "        x[idx] = tmp_x + h\n",
    "        fxh = f(x)\n",
    "        x[idx] = tmp_x = h\n",
    "        fx = f(x)\n",
    "        grads[idx]  = (fxh-fx)/2*h\n",
    "        x[idx] = tmp_x\n",
    "        it.iternext()\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x,t,lr):\n",
    "    lr = 1e-4\n",
    "    y = predict(x)\n",
    "    loss = lambda x: cross_entropy(y,t)\n",
    "    gred_desc1 = numerical_gradient2(loss, W1)\n",
    "    gred_desc2 = numerical_gradient2(loss, W2)\n",
    "    gred_desc3 = numerical_gradient2(loss, W3)\n",
    "    gred_desc1_b = numerical_gradient2(loss, b1)\n",
    "    gred_desc2_b = numerical_gradient2(loss, b2)\n",
    "    gred_desc3_b = numerical_gradient2(loss, b3)\n",
    "    W1 = W1 - gred_desc1 * lr\n",
    "    W2 = W2 - gred_desc2 * lr\n",
    "    W3 = W3 - gred_desc3 * lr\n",
    "    b1 = b1 = gred_desc1_b * lr\n",
    "    b2 = b2 = gred_desc2_b * lr\n",
    "    b3 = b3 = gred_desc3_b * lr\n",
    "    return W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.W1 = np.random.randn(784)\n",
    "        self.b1 = np.zeros(258)\n",
    "        self.W2 = np.random.randn(258)\n",
    "        self.b2 = np.zeros(10)\n",
    "\n",
    "    def predict(self, x):\n",
    "        l1 = np.dot(x,self.W1) + self.b1\n",
    "        z1 = relu(l1)\n",
    "        l2 = np.dot(z1,self.W2) + self.b2\n",
    "        pred = softmax(l2)\n",
    "        return pred\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        loss = cross_entropy(y,t)\n",
    "        return loss\n",
    "\n",
    "    def gradient_descent(self, x, t, lr):\n",
    "        W_loss = lambda W: self.loss(x, t)\n",
    "        gred_desc1 = numerical_gradient(W_loss, self.W1)\n",
    "        gred_desc2 = numerical_gradient(W_loss, self.W2)\n",
    "        gred_desc1_b = numerical_gradient(W_loss, self.b1)\n",
    "        gred_desc2_b = numerical_gradient(W_loss, self.b2)\n",
    "        self.W1 = self.W1 - gred_desc1 * lr\n",
    "        self.W2 = self.W2 - gred_desc2 * lr\n",
    "        self.b1 = self.b1 = gred_desc1_b * lr\n",
    "        self.b2 = self.b2 = gred_desc2_b * lr\n",
    "        return self.W1\n",
    "\n",
    "    def accuracy(self,x,t):\n",
    "        result = np.argmax(self.predict(x), axis=1) == np.argmax(t,axis=1)\n",
    "        result = np.sum(result)/x.shape[0]\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = make_one(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (60000,28,28) and (784,258) not aligned: 28 (dim 2) != 784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\sbhoon\\worksapace\\test7_1.ipynb 셀 21\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=0'>1</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=2'>3</a>\u001b[0m     network\u001b[39m.\u001b[39;49mgradient_descent(X_train, y_train, \u001b[39m1e-5\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=3'>4</a>\u001b[0m     losses \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39mloss(X_train,y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=4'>5</a>\u001b[0m     acc \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39maccuracy(X_train,y_train)\n",
      "\u001b[1;32md:\\sbhoon\\worksapace\\test7_1.ipynb 셀 21\u001b[0m in \u001b[0;36mNetwork.gradient_descent\u001b[1;34m(self, x, t, lr)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgradient_descent\u001b[39m(\u001b[39mself\u001b[39m, x, t, lr):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=20'>21</a>\u001b[0m     W_loss \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x, t)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=21'>22</a>\u001b[0m     gred_desc1 \u001b[39m=\u001b[39m numerical_gradient(W_loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=22'>23</a>\u001b[0m     gred_desc2 \u001b[39m=\u001b[39m numerical_gradient(W_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=23'>24</a>\u001b[0m     gred_desc1_b \u001b[39m=\u001b[39m numerical_gradient(W_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb1)\n",
      "\u001b[1;32md:\\sbhoon\\worksapace\\test7_1.ipynb 셀 21\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=17'>18</a>\u001b[0m tmp_x \u001b[39m=\u001b[39m x[idx]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=18'>19</a>\u001b[0m x[idx] \u001b[39m=\u001b[39m tmp_x \u001b[39m+\u001b[39m h\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=19'>20</a>\u001b[0m fxh \u001b[39m=\u001b[39m f(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=20'>21</a>\u001b[0m x[idx] \u001b[39m=\u001b[39m tmp_x\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=21'>22</a>\u001b[0m fx \u001b[39m=\u001b[39m f(x)\n",
      "\u001b[1;32md:\\sbhoon\\worksapace\\test7_1.ipynb 셀 21\u001b[0m in \u001b[0;36mNetwork.gradient_descent.<locals>.<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgradient_descent\u001b[39m(\u001b[39mself\u001b[39m, x, t, lr):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=20'>21</a>\u001b[0m     W_loss \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(x, t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=21'>22</a>\u001b[0m     gred_desc1 \u001b[39m=\u001b[39m numerical_gradient(W_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=22'>23</a>\u001b[0m     gred_desc2 \u001b[39m=\u001b[39m numerical_gradient(W_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW2)\n",
      "\u001b[1;32md:\\sbhoon\\worksapace\\test7_1.ipynb 셀 21\u001b[0m in \u001b[0;36mNetwork.loss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, x, t):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=15'>16</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=16'>17</a>\u001b[0m     loss \u001b[39m=\u001b[39m cross_entropy(y,t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n",
      "\u001b[1;32md:\\sbhoon\\worksapace\\test7_1.ipynb 셀 21\u001b[0m in \u001b[0;36mNetwork.predict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=8'>9</a>\u001b[0m     l1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(x,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW1) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=9'>10</a>\u001b[0m     z1 \u001b[39m=\u001b[39m relu(l1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/sbhoon/worksapace/test7_1.ipynb#ch0000021?line=10'>11</a>\u001b[0m     l2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(z1,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW2) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb2\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (60000,28,28) and (784,258) not aligned: 28 (dim 2) != 784 (dim 0)"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    network.gradient_descent(X_train, y_train, 1e-5)\n",
    "    losses = network.loss(X_train,y_train)\n",
    "    acc = network.accuracy(X_train,y_train)\n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch+1,\"==========\",\"acc =====\", acc,\"loss =====\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X = load_iris()['data']\n",
    "y = load_iris()['target']\n",
    "y = make_one(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "from typing import Sequence\n",
    "from keras.datasets import mnist\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# 모델 정의하기 (여기에서는 Sequential 클래스 사용)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(28 * 28,)))\n",
    "\n",
    "model.add(layers.Dense(256, activation='sigmoid'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일 하기\n",
    "model.compile(optimizer='sgd',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "996489e7b535382952e1f0cbc47ae133c35cde8716d4996bf342c3a1d61ac153"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
